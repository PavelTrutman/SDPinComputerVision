\chapter{Semidefinite programming}
%TODO Some text about semidefinite programming ...


\section{Preliminaries on semidefinite programs}
We introduce here some notation and preliminaries about symmetric matrices and semidefinite programs.
We will introduce further notation and preliminaries later on in the text when needed.

At the beginning, let us denote the inner product for two vectors $x$, $y \in\R^n$
\begin{eqnarray}
  \langle x, y\rangle &=& \sum_{i=1}^n x_iy_i
\end{eqnarray}
and the Frobenius inner product for two matrices $X$, $Y\in\R^{n\times m}$.
\begin{eqnarray}
  \langle X, Y\rangle &=& \sum_{i=1}^n \sum_{j=1}^m X_{ij}Y_{ij}
\end{eqnarray}

\subsection{Symmetric matrices}
Let $\Sym_n$ denotes the space of $n\times n$ real symmetric matrices.

For matrix $M\in\Sym_n$, the notation $M \succeq 0$ means that $M$ is positive semidefinite.
$M \succeq 0$ if and only if any of the following equivalent properties holds.
\begin{enumerate}
  \item $x^\top Mx \geq 0$ for all $x \in \R^n$.
  \item All eigenvalues of $M$ are nonnegative.
\end{enumerate}

For matrix $M\in\Sym_n$, the notation $M \succ 0$ means that $M$ is positive definite.
$M \succ 0$ if and only if any of the following equivalent properties holds.
\begin{enumerate}
  \item $M \succeq 0$ and $\rank M = n$.
  \item $x^\top Mx > 0$ for all $x \in \R^n$.
  \item All eigenvalues of $M$ are positive.
\end{enumerate}

\subsection{Semidefinite programs}
The standard (primal) form of a semidefinite program in variable $X\in\Sym_n$ is defined as follows:
\begin{eqnarray}
  \begin{array}{rclrrclcll}
    p^* &=& \displaystyle \sup_{X\in\Sym_n} & \multicolumn{3}{l}{\langle C,X\rangle} \\
    && \text{s.t.} & \langle A_i, X\rangle &=& b_i & (i = 1,\ldots,m)\\
    &&& X &\succeq& 0
  \end{array}
\end{eqnarray}
where $C$, $A_1$, \ldots, $A_m \in \Sym_n$ and $b\in\R^m$ are given.

The dual form of the primal form is the following program in variable $y\in\R^m$.
\begin{eqnarray}
  \begin{array}{rclrrclcll}
    d^* &=& \displaystyle \inf_{y\in\R^m} & \multicolumn{3}{l}{b^\top y} \\
    && \text{s.t.} & \displaystyle \sum_{i=1}^m A_iy_i - C &\succeq& 0
  \end{array}
\end{eqnarray}

\section{State of the art review}
%TODO: YALMIP, SEDUMI, MOSEK amd others


\section{Nesterov's approach}
In this section, we will follow Chapter 4 of \cite{Nesterov-2004} by Y. Nesterov, which is devoted to convex minimization problems.
We will extract from it only the minimum, just to be able to introduce a algorithm for SDP programs solving.
We will present some basic definitions and theorems, but we will not prove them.
For the proofs look into \cite{Nesterov-2004}.

\subsection{Self-concordant functions}
\begin{definition}[Self-concordant function in $\R$]
  A closed convex function $f: \R \mapsto \R$ is self-concordant if there exist a constant $M_f \geq 0$ such that the inequality
  \begin{eqnarray}
    |f'''(x)| &\leq& M_f f''(x)^{3/2}
  \end{eqnarray}
  holds for all $x\in\dom f$.
\end{definition}

For better understanding of self-concordant functions, we provide several examples.

\begin{example}~\\[-0.5cm]
  \begin{enumerate}
    \item Linear and convex quadratic functions.
      \begin{eqnarray}
        f'''(x) &=& 0\ \text{ for all } x
      \end{eqnarray}
      Linear and convex quadratic functions are self-concordant with constant $M_f = 0$.
    \item Negative logarithms.
      \begin{eqnarray}
        f(x) &=& -\ln(x)\ \text{ for } x>0\\
        f'(x) &=& -\frac{1}{x}\\
        f''(x) &=& \frac{1}{x^2}\\
        f'''(x) &=& -\frac{2}{x^3}\\
        \frac{|f'''(x)|}{f''(x)^{3/2}} &=& 2
      \end{eqnarray}
      Negative logarithms are self-concordant functions with constant $M_f = 2$.

    \item Exponential functions.
      \begin{eqnarray}
        f(x) &=& e^x\\
        f''(x) \ =\ f'''(x) &=& e^x\\
        \frac{|f'''(x)|}{f''(x)^{3/2}} &=& e^{-x/2} \rightarrow\infty \ \text{ as } x\rightarrow-\infty
      \end{eqnarray}
      Exponential functions are not self-concordant functions.
  \end{enumerate}
\end{example}

\begin{definition}[Self-concordant function in $\R^n$]
  A closed convex function $f: \R^n \mapsto \R$ is self-concordant if function
  \begin{eqnarray}
    g(t) &=& f(x + tv)
  \end{eqnarray}
  is self-concordant for all $x\in\dom f$ and all $v\in\R^n$.
\end{definition}

Now, let us focus on the main properties of self-concordant functions.

\begin{theorem}
  Let functions $f_i$ be self-concordant with constants $M_i$  and let $\alpha_i > 0$, $i = 1,2$. Then the function
 \begin{eqnarray}
   f(x) &=& \alpha_1f_1(x) + \alpha_2f_2(x)
 \end{eqnarray}
 is self-concordant with constant
 \begin{eqnarray}
   M_f &=& \max \bigg\{\frac{1}{\sqrt{\alpha_1}}M_1, \frac{1}{\sqrt{\alpha_2}}M_2\bigg\}
 \end{eqnarray}
 and
 \begin{eqnarray}
   \dom f &=& \dom f_1 \cap \dom f_2.
 \end{eqnarray}
\end{theorem}

\begin{corollary}\labelcol{SDP:scf:scaling}
  Let function $f$ be self-concordant with some constant $M_f$ and $\alpha > 0$. Then the function $\phi(x) = \alpha f(x)$ is also self-concordant with the constant $M_\phi = \frac{1}{\sqrt{\alpha}}M_f$.
\end{corollary}

We call function $f(x)$ as the standard self-concordant function if $f(x)$ is some self-concordant function with the constant $M_f = 2$. Using \refcol{SDP:scf:scaling}, we can see that any self-concordant function can be transformed into the standard self-concordant function by scaling.

\begin{theorem}\labelthe{SDP:scf:hessian}
  Let function $f$ be self-concordant. If $\dom f$ contains no straight line, then the Hessian $f''(x)$ is nondegenerate at any $x$ from $\dom f$.
\end{theorem}

For some self-concordant function $f(x)$, for which we assume, that $\dom f$ contains no straight line (which implies that all $f''(x)$ are nondegenerate, see \refthe{SDP:scf:hessian}), we denote two local norms as
\begin{eqnarray}
  \| u \|_x &=& \sqrt{u^\top f''(x) u}\\
  \| u \|_x^* &=& \sqrt{u^\top f''(x)^{-1} u}.
\end{eqnarray}

Consider following minimization problem
\begin{eqnarray}
  x^* &=& \arg\min_{x\in\dom f} f(x)\labeleq{SDP:scf:minProblem}
\end{eqnarray}
as the minimization of the self-concordant function $f(x)$.
\refalg{SDP:scf} is describing the iterative process of solving optimization problem \refeqb{SDP:scf:minProblem}.
The algorithm is divided into two stages by the value of $\|f'(x_k)\|_{x_k}^*$.
The splitting parameter $\beta$ guarantees quadratic convergence rate for the second part of the algorithm. The parameter $\beta$ is chosen from interval $(0, \bar{\lambda})$, where
\begin{eqnarray}
  \bar{\lambda} &=& \frac{3 - \sqrt{5}}{2},
\end{eqnarray}
which is a root of the equation
\begin{eqnarray}
  \frac{\lambda}{(1-\lambda)^2} &=& 1.
\end{eqnarray}

\input{alg/self-concordant-function.tex}

The first while loop (lines \refalgline{SDP:scf:w1b} -- \refalgline{SDP:scf:w1e}) represents damped Newton method, where at each iteration we have
\begin{eqnarray}
  f(x_k) - f(x_{k+1}) &\geq& \beta - \ln(1+\beta) \text{ for } k \geq 0,
\end{eqnarray}
where
\begin{eqnarray}
  \beta - \ln(1+\beta) &>& 0 \text{ for } \beta > 0,
\end{eqnarray}
and therefore the global convergence of the algorithm is ensured.
It can be shown that the local convergence rate of the damped Newton method is also quadratic, but the presented switching strategy is preferred as it gives better complexity bounds.

The second while loop of the algorithm (lines \refalgline{SDP:scf:w2b} -- \refalgline{SDP:scf:w2e}) is the standard Newton method with quadratic convergence rate.

The algorithm terminates when the required precision $\varepsilon$ is reached.


\subsection{Self-concordant barriers}
To be able to introduce self-concordant barriers, let us denote $\Dom f = \cl(\dom f)$.

\begin{definition}[Self-concordant barrier]\labeldef{SDP:scb:scb}
  Let $F(x)$ be a standard self-concordant function. We call it a $\nu$-self-concordant barrier for set $\Dom F$, if
  \begin{eqnarray}
    \sup_{u\in\R^n} \big(2u^\top F'(x) - u^\top F''(x) u\big) &\leq& \nu \labeleq{SDP:scb:def}
  \end{eqnarray}
  for all $x\in\dom F$. The value $\nu$ is called the parameter of the barrier.
\end{definition}

The inequality \refeqb{SDP:scb:def} can be rewritten into the following equivalent matrix notation:
\begin{eqnarray}
  F''(x) &\succeq& \frac{1}{\nu}F'(x)F'(x)^\top.\labeleq{SDP:scb:def1}
\end{eqnarray}

In \refdef{SDP:scb:scb}, the hessian $F''(x)$ is not required to be nondegenerate. However, in case that $F''(x)$ is nondegenerate, the inequality \refeqb{SDP:scb:def} is equivalent to
\begin{eqnarray}
  F'^\top(x)F''(x)^{-1}F'(x) &\leq& \nu.\labeleq{SDP:scb:def2}
\end{eqnarray}

Let us explore, which basic functions are self-concordant barriers.

\begin{example}~\\[-0.5cm]
  \begin{enumerate}
    \item Linear functions.
      \begin{eqnarray}
        F(x) &=& \alpha + a^\top x,\ \dom F = \R^n\\
        F''(x) &=& 0
      \end{eqnarray}
      From \refeqb{SDP:scb:def1} and for $a \neq 0$ follows, that linear functions are not self-concordant barriers.

    \item Convex quadratic functions.\\
      For $A = A^\top \succ 0$:
      \begin{eqnarray}
        F(x) &=& \alpha + a^\top x + \frac{1}{2} x^\top Ax,\ \dom F = \R^n\\
        F'(x) &=& a + Ax\\
        F''(x) &=& A
      \end{eqnarray}
      After substitution into \refeqb{SDP:scb:def2} we obtain
      \begin{eqnarray}
        (a + Ax)^\top A^{-1}(a + Ax) &=& a^\top A^{-1}a + 2a^\top x + x^\top Ax,
      \end{eqnarray}
      which is unbounded from above on $\R^n$. Therefore, quadratic functions are not self-concordant barriers.
      

    \item Logarithmic barrier for a ray.
      \begin{eqnarray}
        F(x) &=& -\ln x,\ \dom F = \{x\in\R\ |\ x > 0\}\\
        F'(x) &=& -\frac{1}{x}\\
        F''(x) &=& \frac{1}{x^2}
      \end{eqnarray}
      From \refeqb{SDP:scb:def2}, when $F'(x)$ and $F''(x)$ are both scalars, we get
      \begin{eqnarray}
        \frac{F'(x)^2}{F''(x)} &=& \frac{x^2}{x^2}\ =\ 1.
      \end{eqnarray}
      Therefore, the logarithmic barrier for a ray is a self-concordant barrier with parameter $\nu = 1$ on domain $\{x\in\R\ |\ x > 0\}$.
  \end{enumerate}
\end{example}

Now, let us focus on the main properties of self-concordant barriers.

\begin{theorem}\labelthe{SDP:scb:penaltyFunction}
  Let $F(x)$ be a self-concordant barrier. Then the function $c^\top x + F(x)$ is a self-concordant function on $\dom F$.
\end{theorem}

\begin{theorem}
  Let $F_i$ be $\nu_i$-self-concordant barriers, $i = 1,2$. Then the function
  \begin{eqnarray}
    F(x) &=& F_1(x) + F_2(x)
  \end{eqnarray}
  is a self-concordant barrier for convex set
  \begin{eqnarray}
    \Dom F &=& \Dom F_1 \cap \Dom F_2
  \end{eqnarray}
  with the parameter
  \begin{eqnarray}
    \nu &=& \nu_1 + \nu_2.
  \end{eqnarray}
\end{theorem}

\begin{theorem}\labelthe{SDP:scb:distance}
  Let $F(x)$ be a $\nu$-self-concordant barrier. Then for any $x\in\Dom F$ and $y\in\Dom F$ such that
  \begin{eqnarray}
    (y-x)^\top F'(x) &\geq& 0,
  \end{eqnarray}
  we have
  \begin{eqnarray}
    \|y-x\|_x &\leq& \nu + 2\sqrt{\nu}.
  \end{eqnarray}
\end{theorem}

There is one special point of convex set, which is important for solving convex minimization problem. 
It is called analytic center of convex set and we will focus on its properties.

\begin{definition}
  Let $F(x)$ be a $\nu$-self-concordant barrier for the set $\Dom F$. The point
  \begin{eqnarray}
    x^*_F &=& \arg \min_{x\in\Dom F} F(x) \labeleq{SDP:scb:ac}
  \end{eqnarray}
  is called the analytic center of convex set $\Dom F$, generated by the barrier $F(x)$.
\end{definition}

\begin{theorem}
  Assume that the analytic center of a $\nu$-self-concordant barrier $F(x)$ exists. Then for any $x\in\Dom F$ we have
  \begin{eqnarray}
    \|x-x^*_F\|_{x^*_F} &\leq& \nu + 2\sqrt{\nu}.
  \end{eqnarray}
\end{theorem}

This property clearly follows from \refthe{SDP:scb:distance} and the fact, that $F'(x^*_F) = 0$.

Thus, if $\Dom F$ contains no straight line, then the existence of $x^*_F$ (which leads to nondegenerate $F''(x^*_F)$) implies, that the set $\Dom F$ is bounded.

Now, we describe the algorithm and its properties for obtaining an approximation to the analytic center.
To find the analytic center, we need to solve the minimization problem \refeqb{SDP:scb:ac}.
For that, we will use the standard implementation of the damped Newton method with termination condition
\begin{eqnarray}
  \|F'(x_k)\|^*_{x_k} &\leq& \beta, \text{ for } \beta\in(0,1).
\end{eqnarray}
The pseudocode of the whole minimization process is shown in \refalg{SDP:scb:ac}.

\input{alg/analytic-center.tex}

\begin{theorem}
  \refalg{SDP:scb:ac} terminates no later than after $N$ steps, where
  \begin{eqnarray}
    N &=& \frac{1}{\beta - \ln(1+\beta)}\big(F(x_0) - F(x^*_F)\big).
  \end{eqnarray}
\end{theorem}

The knowledge of analytic center allows us to solve the standard minimization problem
\begin{eqnarray}
  x^* &=& \arg\min_{x\in Q} c^\top x \labeleq{SDP:scb:standardProblem}
\end{eqnarray}
with bounded closed convex set $Q \equiv \Dom F$, which has nonempty interior, and which is endowed with a $\nu$-self-concordant barrier $F(x)$.
Denote
\begin{eqnarray}
  f(t,x) &=& tc^\top x + F(x), \text{ for } t \geq 0
\end{eqnarray}
as a parametric penalty function.
Using \refthe{SDP:scb:penaltyFunction} we can see, that $f(t,x)$ is self-concordant in $x$.
Let us introduce new minimization problem using the parametric penalty function $f(t,x)$
\begin{eqnarray}
  x^*(t) &=& \arg\min_{x\in\dom F} f(t,x).
\end{eqnarray}
This trajectory is called the central path of the problem \refeqb{SDP:scb:standardProblem}.
We will reach the solution $x^*(t) \rightarrow x^*$ as $t \rightarrow \infty$.
Moreover, since the set $Q$ is bounded, the analytic center $x^*_F$ of this set exists and
\begin{eqnarray}
  x^*(0) &=& x^*_F.
\end{eqnarray}
From the first-order optimality condition, any point of the central path satisfies equation
\begin{eqnarray}
  tc + F'\big(x^*(t)\big) &=& 0
\end{eqnarray}
Since the analytic center lies on the central path and can be found by \refalg{SDP:scb:ac}, all we have to do, to find the solution $x^*$, is to follow the central path. 
This enables us an approximate centering condition:
\begin{eqnarray}
  \|f'(t,x)\|^*_x\ =\ \|tc + F'(x)\|^*_x &\leq& \beta, \labeleq{SDP:scb:cntrCondition}
\end{eqnarray}
where the centering parameter $\beta$ is small enough.

Assuming $x\in\dom F$, one iteration of the path-following algorithm consists of two steps:
\begin{eqnarray}
  t_+ &=& t + \frac{\gamma}{\|c\|^*_x},\\
  x_+ &=& x - F''(x)^{-1}\big(t_+c+F'(x)\big).
\end{eqnarray}

\begin{theorem}
  Let $x$ satisfy the approximate centering condition \refeqb{SDP:scb:cntrCondition}
  \begin{eqnarray}
    \|tc + F'(x)\|^*_x &\leq& \beta
  \end{eqnarray}
  with $\beta < \bar{\lambda} = \frac{3-\sqrt{5}}{2}$.
  Then for $\gamma$, such that
  \begin{eqnarray}
    |\gamma| &\leq& \frac{\sqrt{\beta}}{1+\sqrt{\beta}} - \beta,
  \end{eqnarray}
  we have again
  \begin{eqnarray}
    \|t_+c + F'(x_+)\|^*_{x_+} &\leq& \beta.
  \end{eqnarray}
\end{theorem}

This theorem ensures the correctness of the presented iteration of the path-following algorithm. For the whole description of the path-following algorithm, please see \refalg{SDP:scb:pf}.

\input{alg/path-follow.tex}

\begin{theorem}
  \refalg{SDP:scb:pf} terminates no more than after $N$ steps, where
  \begin{eqnarray}
    N &\leq& \mathcal{O}\Bigg(\sqrt{\nu}\ln\frac{\nu \|c\|^*_{x^*_F}}{\epsilon}\Bigg).
  \end{eqnarray}
\end{theorem}

The parameters $\beta$ and $\gamma$ in \refalg{SDP:scb:ac} and \refalg{SDP:scb:pf} can be fixed. The reasonable values are:
\begin{eqnarray}
  \beta &=& \frac{1}{9},\\
  \gamma &=& \frac{\sqrt{\beta}}{1+\sqrt{\beta}} - \beta\ =\ \frac{5}{36}.
\end{eqnarray}

The union of \refalg{SDP:scb:ac} and \refalg{SDP:scb:pf} can be easily used to solve the standard minimization problem \refeqb{SDP:scb:standardProblem}, supposing we have a feasible point $x_0\in Q$.

\subsection{Barrier function for semidefinite programming}


\section{Implementation details}
%TODO about the code

\section{Comparison with the state of the art methods}
%TODO some graphs

